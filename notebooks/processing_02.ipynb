{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8SleKRtTDoJ"
      },
      "source": [
        "<h1 style=\"text-align: center;\">&nbsp;<img style=\"font-size: 0.9em;\" src=\"https://www.hospitalitynet.org/picture/153007157/travelers-push-tripadvisor-past-1-billion-reviews-opinions.jpg?t=1587981992\" alt=\"\" width=\"300\" height=\"100\" /><span style=\"font-family: tahoma, arial, helvetica, sans-serif; font-size: large;\"><span style=\"font-size: x-large;\"> Preprocessing des donn√©es avec PySpark</span></span><span style=\"font-family: tahoma, arial, helvetica, sans-serif; font-size: large;\">&nbsp; &nbsp; &nbsp;&nbsp;</span>&nbsp;<img src=\"https://i0.wp.com/mosefparis1.fr/wp-content/uploads/2022/10/cropped-image-1.png?fit=532%2C540&amp;ssl=1\" alt=\"\" width=\"150\" height=\"150\" />&nbsp;</h1>\n",
        "<p style=\"text-align: center;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;de Lucie Gabagnou et Yanis Rehoune</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptILyCEMT0ie"
      },
      "source": [
        "Dans ce second notebook, nous effectuons une pipeline de preprocessing des donn√©es: Les donn√©es brutes qui ont √©t√© extraites par Webscraping ne sont pas forc√©ment dans le format attendu. Il faut ainsi nettoyer les donn√©es et extraire des features pertinents.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYKefruS5iI9"
      },
      "source": [
        "# Processing avec PySpark\n",
        "Dans cette partie, nous r√©alisons le processing de nos donn√©es: on nettoie (le texte particuli√®rement) et √©ventuellement cr√©er de nouveaux features √† partir de la base brute r√©colt√©e. Ici, il faut s'assurer que les types soient les bons, que le texte soit exploitable pour le NLP, et que tous les features soient exploitables (typiquement l'adresse doit devenir un ensemble de coordonn√©es g√©ographiques..).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Dans notre cas, Pyspark s'av√®re pratique pour ex√©cuter facilement des fonctions sur un nombre de lignes  important. \n",
        "A l'issue de cette √©tape, les donn√©es seront pr√™tes pour l'analyse exploratoire et le ML.\n",
        "Remarque: il n'y a pas d'√©tapes interm√©diaires pour voir les donn√©es car on √©vite d'utiliser les fonctions .show() qui puisent dans la m√©moire vive et sont longues.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "REMARQUE: \n",
        "- Si vous utilisez PySpark en local, assurez-vous d'avoir bien install√© PySpark (cf README)\n",
        "- Si vous utilisez PySpark sur google colab, assurez-vous d'avoir un dossier sur le drive comportant le projet!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dj9e4kU7vmt"
      },
      "source": [
        "#### Installation de l'environnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/pyspark'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import findspark\n",
        "import os\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On d√©finit un chemin actuel √† la racine du projet pour acc√©der facilement aux contenus des autres modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x0dR8WA078lG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current path /Users/luciegabagnou/Documents/MOSEF/PYTHON/projet_trip_advisor/sentiment_analysis_tripadvisor\n"
          ]
        }
      ],
      "source": [
        "current_path=os.path.dirname(os.getcwd())\n",
        "os.chdir(current_path)\n",
        "print(\"Current path\",os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJNrwNHW1ATf"
      },
      "source": [
        "### Cr√©ation d'un SparkDataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ykjaJ3t8MkF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.8.0)\n",
            "Requirement already satisfied: pyspark in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: findspark in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: requests in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.28.2)\n",
            "Requirement already satisfied: mysqlclient in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.1.1)\n",
            "Requirement already satisfied: unidecode in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.3.6)\n",
            "Requirement already satisfied: scrapy in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (2.7.1)\n",
            "Requirement already satisfied: bs4 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.0.1)\n",
            "Requirement already satisfied: undetected-chromedriver in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (3.2.1)\n",
            "Requirement already satisfied: spacy in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (3.6.3)\n",
            "Requirement already satisfied: pandas in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (1.5.3)\n",
            "Requirement already satisfied: python-dotenv in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (0.21.1)\n",
            "Requirement already satisfied: plotly in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (5.2.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (1.2.1)\n",
            "Requirement already satisfied: wordcloud in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (1.8.2.2)\n",
            "Requirement already satisfied: textblob in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (0.17.1)\n",
            "Requirement already satisfied: geopy in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 1)) (0.22.0)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 1)) (1.26.14)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 1)) (0.9.2)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from pyspark->-r requirements.txt (line 2)) (0.10.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from requests->-r requirements.txt (line 4)) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from requests->-r requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: packaging in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (21.3)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (5.5.2)\n",
            "Requirement already satisfied: protego>=0.1.15 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (0.2.1)\n",
            "Requirement already satisfied: tldextract in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (1.6.2)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (2.1.1)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: cryptography>=3.3 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (38.0.4)\n",
            "Requirement already satisfied: lxml>=4.3.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (4.9.2)\n",
            "Requirement already satisfied: setuptools in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (65.6.3)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (1.7.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (21.1.0)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (2.0.6)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (23.0.0)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (22.10.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (1.0.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from bs4->-r requirements.txt (line 8)) (4.11.1)\n",
            "Requirement already satisfied: websockets in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from undetected-chromedriver->-r requirements.txt (line 9)) (10.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (3.1.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (8.1.7)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (3.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.23.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (2.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (2.4.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.10.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (6.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (9.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 12)) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from plotly->-r requirements.txt (line 14)) (8.1.0)\n",
            "Requirement already satisfied: six in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from plotly->-r requirements.txt (line 14)) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 15)) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 15)) (1.10.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: nltk>=3.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from textblob->-r requirements.txt (line 17)) (3.8.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from geopy->-r requirements.txt (line 18)) (2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from cryptography>=3.3->scrapy->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from itemloaders>=1.0.1->scrapy->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: click in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from nltk>=3.1->textblob->-r requirements.txt (line 17)) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from nltk>=3.1->textblob->-r requirements.txt (line 17)) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->-r requirements.txt (line 10)) (4.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy->-r requirements.txt (line 7)) (22.2.0)\n",
            "Requirement already satisfied: pyasn1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy->-r requirements.txt (line 7)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy->-r requirements.txt (line 7)) (0.2.8)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 10)) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 10)) (0.0.4)\n",
            "Requirement already satisfied: outcome in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: sniffio in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy->-r requirements.txt (line 7)) (22.10.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy->-r requirements.txt (line 7)) (15.1.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy->-r requirements.txt (line 7)) (21.0.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy->-r requirements.txt (line 7)) (22.10.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium->-r requirements.txt (line 1)) (1.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 8)) (2.3.2.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from jinja2->spacy->-r requirements.txt (line 10)) (2.1.2)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from tldextract->scrapy->-r requirements.txt (line 7)) (3.9.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from tldextract->scrapy->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: pycparser in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->scrapy->-r requirements.txt (line 7)) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n",
        "#!python -m spacy download fr_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-qjJ-2Pq1ATg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from pyspark import  HiveContext , SparkContext\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, DoubleType\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "import re\n",
        "from scripts.utils import get_digits\n",
        "from scripts.preprocessor.global_processor import geocode_address,separate_price_and_cuisine\n",
        "from scripts.preprocessor.text_processor import clean_text_sentiment_analysis\n",
        "import nltk\n",
        "import spacy\n",
        "from unidecode import unidecode\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VWBsExlBveq"
      },
      "source": [
        "Dans un premier temps, on cr√©er une session Spark, celle sur laquelle on va load le dataframe et effectuer nos modifications. Dans le notebook, on load un DataFrame, mais dans la partie d√©veloppement, on exectuera cela sur la base MySQL. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8iBOMHSL1ATj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------------+--------------------+--------------+--------------------+---------+--------------------+--------------------+\n",
            "|average_note|            location|                name|number_reviews|  price_and_cuisines|  ranking|             reviews|                 url|\n",
            "+------------+--------------------+--------------------+--------------+--------------------+---------+--------------------+--------------------+\n",
            "|         4,5|149 boulevard Vol...|        Cafe Leopard|            97|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|    N¬∫¬†39|[Caf√© Leopard, al...|https://www.tripa...|\n",
            "|         4,0|68 Rue de Grenell...|       Cuillier Caf√©|             7|           [‚Ç¨, Caf√©]|   N¬∫¬†708|[Bon petit go√ªter...|https://www.tripa...|\n",
            "|         4,0|40 rue Gregoire d...|          Oenosteria|           138|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Italienn...| N¬∫¬†2‚ÄØ485|[A √©viter absolum...|https://www.tripa...|\n",
            "|         4,5|9 Rue Joseph de M...|           La Bossue|           480|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|   N¬∫¬†174|[Superbe exp√©rien...|https://www.tripa...|\n",
            "|         4,0|7 Rue du Faubourg...|            Baranaan|           256|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Indienne...| N¬∫¬†1‚ÄØ742|[Concept sympa:Pe...|https://www.tripa...|\n",
            "|         3,5|108 Rue de la Roq...|        La Fee Verte|           307|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|   N¬∫¬†131|[Super:Superbe ex...|https://www.tripa...|\n",
            "|         4,5|4 Avenue Carnot, ...|        Le Vin Coeur|           675|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|   N¬∫¬†261|[Tr√®s bonne soir√©...|https://www.tripa...|\n",
            "|         5,0|210 Rue Saint-Mau...|         Leo Bistrot|             1|                  []|N¬∫¬†11‚ÄØ602|                  []|https://www.tripa...|\n",
            "|         5,0|80 boulevard Rasp...|           Foodelice|            13|[‚Ç¨, Caf√©, Restaur...|   N¬∫¬†423|[Tr√®s bonne adres...|https://www.tripa...|\n",
            "|         3,5|16 Place des Abbe...|Une Glace √† Paris...|            10|   [‚Ç¨‚Ç¨‚Ç¨‚Ç¨, Fran√ßaise]| N¬∫¬†5‚ÄØ854|[Service horrible...|https://www.tripa...|\n",
            "|         5,0|32 avenue louis p...|FOOD FACTORY Bagneux|             1|                  []|N¬∫¬†12‚ÄØ301|[Commande Uber ea...|https://www.tripa...|\n",
            "|         3,0|68 rue Saint Deni...|  Hall's Beer Tavern|           107|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|N¬∫¬†13‚ÄØ190|[Un service au to...|https://www.tripa...|\n",
            "|         4,5|36 boulevard Dide...|Cafe Minute Papillon|            69| [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßaise]| N¬∫¬†1‚ÄØ899|[Fort sympathique...|https://www.tripa...|\n",
            "|         4,0|55 Rue Montmartre...|     Pizz'aria Paris|             1|     [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Pizza]|   N¬∫¬†667|[Tr√®s bonnes pizz...|https://www.tripa...|\n",
            "|         3,0|271 avenue Daumes...|Pizzeria Villa Ro...|            87|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Italienn...| N¬∫¬†3‚ÄØ423|[Un restaurant qu...|https://www.tripa...|\n",
            "|         4,5|9 Place de l‚ÄôAdju...|         Grill House|             3| [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßaise]| N¬∫¬†5‚ÄØ039|[NE PAS SE FIER Q...|https://www.tripa...|\n",
            "|         4,5|110 boulevard de ...|Le Diplomate Pari...|            93|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...| N¬∫¬†1‚ÄØ642|[Adresse √† reteni...|https://www.tripa...|\n",
            "|         4,5|71 rue des Gravil...|          Ai's Bento|            29|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Chinoise...|   N¬∫¬†593|[Cuisine asiatiqu...|https://www.tripa...|\n",
            "|         3,5|42 rue Mazarine, ...|  Le Bistrot Mazarin|           283|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...| N¬∫¬†4‚ÄØ934|[Une excellente b...|https://www.tripa...|\n",
            "|         4,0|35 rue de Rivoli,...|               Bayan|            28|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Chinoise...| N¬∫¬†6‚ÄØ106|[Excellent üëå:Bon...|https://www.tripa...|\n",
            "+------------+--------------------+--------------------+--------------+--------------------+---------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName(\"Load JSON\").getOrCreate()\n",
        "df = spark.read.option(\"multiline\",\"true\").json(\"data/fetch_data.json\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv8OyTtdCY5i"
      },
      "source": [
        "Dans un premier temps, on s'assure que les types soient corrects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9rcNN6f6BAX5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- average_note: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- number_reviews: string (nullable = true)\n",
            " |-- price_and_cuisines: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ranking: string (nullable = true)\n",
            " |-- reviews: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- url: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdkxSDOhDU7T"
      },
      "source": [
        "On voit que \"average note\" est en string alors qu'il doit s'agir de nombres d√©cimaux, de m√™me pour le nombre de reviews, le classement (ranking).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzjRAkoQDX6P"
      },
      "source": [
        "#### Type \n",
        "On corrige les types qui posaient probl√®mes pr√©c√®demment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1Ssfw0u_H4EH"
      },
      "outputs": [],
      "source": [
        "# Cr√©ation d'une fonction d√©finie par utilisateur (udf). On a repris la fonction get_digits disponibles dans les utils\n",
        "# Application sur la colonne des classements pour r√©cup√©rer les chiffres/nombres de la cha√Æne de caract√®res n¬∞1 => 1\n",
        "# Apply UDF to the column \"tripadvisor rank\"\n",
        "from pyspark.sql.functions import col, lit, regexp_replace\n",
        "get_digits_udf = udf(get_digits, DoubleType())\n",
        "df = df.withColumn(\"average_note\", regexp_replace(col(\"average_note\"), \",\", \".\"))\n",
        "df = df.withColumn(\"ranking\", get_digits_udf(df[\"ranking\"]))\n",
        "df = df.withColumn(\"average_note\", get_digits_udf(df[\"average_note\"]))\n",
        "df = df.withColumn(\"number_reviews\", get_digits_udf(df[\"number_reviews\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "99aLa4t19Gic"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- average_note: double (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- number_reviews: double (nullable = true)\n",
            " |-- price_and_cuisines: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ranking: double (nullable = true)\n",
            " |-- reviews: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- url: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8CgKloJ24L-7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 32:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------------------+\n",
            "|average_note|            location|                name|number_reviews|  price_and_cuisines|ranking|             reviews|                 url|\n",
            "+------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------------------+\n",
            "|         4.5|149 boulevard Vol...|        Cafe Leopard|          97.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|   39.0|[Caf√© Leopard, al...|https://www.tripa...|\n",
            "|         4.0|68 Rue de Grenell...|       Cuillier Caf√©|           7.0|           [‚Ç¨, Caf√©]|  708.0|[Bon petit go√ªter...|https://www.tripa...|\n",
            "|         4.0|40 rue Gregoire d...|          Oenosteria|         138.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Italienn...| 2485.0|[A √©viter absolum...|https://www.tripa...|\n",
            "|         4.5|9 Rue Joseph de M...|           La Bossue|         480.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|  174.0|[Superbe exp√©rien...|https://www.tripa...|\n",
            "|         4.0|7 Rue du Faubourg...|            Baranaan|         256.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Indienne...| 1742.0|[Concept sympa:Pe...|https://www.tripa...|\n",
            "|         3.5|108 Rue de la Roq...|        La Fee Verte|         307.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|  131.0|[Super:Superbe ex...|https://www.tripa...|\n",
            "|         4.5|4 Avenue Carnot, ...|        Le Vin Coeur|         675.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|  261.0|[Tr√®s bonne soir√©...|https://www.tripa...|\n",
            "|         5.0|210 Rue Saint-Mau...|         Leo Bistrot|           1.0|                  []|11602.0|                  []|https://www.tripa...|\n",
            "|         5.0|80 boulevard Rasp...|           Foodelice|          13.0|[‚Ç¨, Caf√©, Restaur...|  423.0|[Tr√®s bonne adres...|https://www.tripa...|\n",
            "|         3.5|16 Place des Abbe...|Une Glace √† Paris...|          10.0|   [‚Ç¨‚Ç¨‚Ç¨‚Ç¨, Fran√ßaise]| 5854.0|[Service horrible...|https://www.tripa...|\n",
            "|         5.0|32 avenue louis p...|FOOD FACTORY Bagneux|           1.0|                  []|12301.0|[Commande Uber ea...|https://www.tripa...|\n",
            "|         3.0|68 rue Saint Deni...|  Hall's Beer Tavern|         107.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...|13190.0|[Un service au to...|https://www.tripa...|\n",
            "|         4.5|36 boulevard Dide...|Cafe Minute Papillon|          69.0| [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßaise]| 1899.0|[Fort sympathique...|https://www.tripa...|\n",
            "|         4.0|55 Rue Montmartre...|     Pizz'aria Paris|           1.0|     [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Pizza]|  667.0|[Tr√®s bonnes pizz...|https://www.tripa...|\n",
            "|         3.0|271 avenue Daumes...|Pizzeria Villa Ro...|          87.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Italienn...| 3423.0|[Un restaurant qu...|https://www.tripa...|\n",
            "|         4.5|9 Place de l‚ÄôAdju...|         Grill House|           3.0| [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßaise]| 5039.0|[NE PAS SE FIER Q...|https://www.tripa...|\n",
            "|         4.5|110 boulevard de ...|Le Diplomate Pari...|          93.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...| 1642.0|[Adresse √† reteni...|https://www.tripa...|\n",
            "|         4.5|71 rue des Gravil...|          Ai's Bento|          29.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Chinoise...|  593.0|[Cuisine asiatiqu...|https://www.tripa...|\n",
            "|         3.5|42 rue Mazarine, ...|  Le Bistrot Mazarin|         283.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Fran√ßais...| 4934.0|[Une excellente b...|https://www.tripa...|\n",
            "|         4.0|35 rue de Rivoli,...|               Bayan|          28.0|[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨, Chinoise...| 6106.0|[Excellent üëå:Bon...|https://www.tripa...|\n",
            "+------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aftIph6tIuoW"
      },
      "source": [
        "Les types ont bien √©t√© corrig√©s."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Traitement des valeurs manquantes\n",
        "On traite les valeurs manquantes sur les variables num√©riques, qui sont celles pouvant ne pas √™tre remplies (pas de reviews => pas de nb reviews, pas de note moyenne)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.na.fill({\n",
        "    \"average_note\": 0,\n",
        "    \"ranking\": 0,\n",
        "    \"number_reviews\": 0\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQlRI4bqIxuR"
      },
      "source": [
        "### Feature engineering:\n",
        "- On va s√©parer le contenu de la colonne \"price and cuisines\", qui regroupe le prix et les types de cuisine. Nous ne l'avons pas fait lors du webscrapping sachant qu'il n'√©tait pas √©vident de s√©parer le contenu: \n",
        "- G√©olocalisation: on veut r√©cup√©rer les coordonn√©es g√©ographiques pour l'appli.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWr35HyQJUZP"
      },
      "source": [
        "##### Price and cuisines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNOrakBAJZEy"
      },
      "source": [
        "En effet, on voit qu'il n'est pas √©vident de trouver une r√®gle simple de s√©paration car le nombre d'√©lements n'est pas le m√™me selon les restaurants (parfois aucune information, parfois 4, parfois prix, parfois non, etc..):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5yNxU5R_J7Ij"
      },
      "outputs": [],
      "source": [
        "\n",
        "# On impose un sch√©ma pour faire en sorte d'avoir le format final souhait√©, √† savoir des listes/arrays de cha√Æne de caract√®res\n",
        "udf_separate_price_and_cuisine = udf(separate_price_and_cuisine, StructType([\n",
        "    StructField(\"price\", ArrayType(StringType())),\n",
        "    StructField(\"cuisine\", ArrayType(StringType()))\n",
        "])) # On renseigne ce sch√©ma dans l' udf\n",
        "\n",
        "#On applique les fonctions\n",
        "df = df.withColumn(\"price\", udf_separate_price_and_cuisine(\"price_and_cuisines\").price) \n",
        "df = df.withColumn(\"cuisine\", udf_separate_price_and_cuisine(\"price_and_cuisines\").cuisine)\n",
        "df = df.drop(*[\"price_and_cuisines\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqd0VsPkLZ7N"
      },
      "source": [
        "##### Localisation\n",
        "On utilise le package geopy pour convertir nos adresses en coordonn√©es GPS: On cr√©√©e une colonne pour la longitude et une pour la latitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "skSPkq5VC-5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "from pyspark.sql.functions import udf,mean\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType\n",
        "from scripts.preprocessor.global_processor import geocode_address\n",
        "\n",
        "geocode_udf = udf(\n",
        "            geocode_address,\n",
        "            returnType = StructType([\n",
        "    StructField(\"latitude\", DoubleType()),\n",
        "    StructField(\"longitude\",DoubleType())]))\n",
        "\n",
        "df = df.repartition(20) \n",
        "df = df.withColumn(\"longitude\", geocode_udf(\"location\").longitude)\n",
        "df = df.withColumn(\"latitude\", geocode_udf(\"location\").latitude)\n",
        "\n",
        "#On fill par la moyenne\n",
        "\n",
        "avg_longitude = df.agg(mean(df[\"longitude\"])).first()[0]\n",
        "avg_latitude = df.agg(mean(df[\"latitude\"])).first()[0]\n",
        "df = df.fillna(avg_longitude, subset=\"longitude\")\n",
        "df = df.fillna(avg_latitude, subset=\"latitude\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYc6hi_zdhhl"
      },
      "source": [
        "##### Commentaires\n",
        "Pour les commentaires, on applique notre pipeline NLP qui a pour objectif de nettoyer un ensemble de commentaires en vue d'une analyse de sentiment. Elle effectue plusieurs op√©rations de nettoyage, telles que la conversion en minuscules, la suppression de caract√®res sp√©ciaux et de chiffres, la suppression de mots-cl√©s, la lemmatisation et la suppression d'entit√©s nomm√©es. Elle utilise la biblioth√®que spaCy pour la lemmatisation et la suppression d'entit√©s nomm√©es. Enfin, la fonction retourne une liste de commentaires nettoy√©s. De plus, elle r√©cup√®re les notes associ√©es aux commentaires dans une autre colonne pour compl√©ter cette analyse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YDhSp_oYivGi"
      },
      "outputs": [],
      "source": [
        "udf_text_cleaning = udf(clean_text_sentiment_analysis, StructType([\n",
        "    StructField(\"reviews\", ArrayType(StringType())),\n",
        "    StructField(\"ratings\", ArrayType(StringType()))]))\n",
        "\n",
        "\n",
        "df=df.withColumn(\"clean_reviews\", udf_text_cleaning(\"reviews\").reviews)\n",
        "df=df.withColumn(\"ratings\", udf_text_cleaning(\"reviews\").ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Conversion des donn√©es\n",
        "On passe par Pandas car cela nous permet d'√©viter des probl√®mes de conversion (les m√©thodes df.write... ne sont pas particuli√®rement adapt√© √† nos donn√©es)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6z7vu6LyOrlK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to                        (0 + 1) / 1]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "clean_data=df.toPandas() # Environ 10 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_note</th>\n",
              "      <th>location</th>\n",
              "      <th>name</th>\n",
              "      <th>number_reviews</th>\n",
              "      <th>ranking</th>\n",
              "      <th>reviews</th>\n",
              "      <th>url</th>\n",
              "      <th>price</th>\n",
              "      <th>cuisine</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>clean_reviews</th>\n",
              "      <th>ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>39 Avenue de l'Op√©ra, 75002 Paris France</td>\n",
              "      <td>Bar E7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12392.0</td>\n",
              "      <td>[Bons cocktails et tapas-cuisine imparfaite:Un...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2.333227</td>\n",
              "      <td>48.868499</td>\n",
              "      <td>[bon cocktail tapa cuisine imparfait grand cho...</td>\n",
              "      <td>[4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>54 rue Piat, 75020 Paris France</td>\n",
              "      <td>God Bless Broccoli</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4346.0</td>\n",
              "      <td>[D√©jeuner:Nous avons manger des tr√®s bonne piz...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨]</td>\n",
              "      <td>[Italienne, Pizza, V√©g√©tariens bienvenus]</td>\n",
              "      <td>2.383660</td>\n",
              "      <td>48.873115</td>\n",
              "      <td>[dejeuner manger bon pizza faire manger super ...</td>\n",
              "      <td>[5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Avenue des 4 Chemins, 92330 Sceaux, 92330 Pari...</td>\n",
              "      <td>Sushi Robinson</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12314.0</td>\n",
              "      <td>[Meilleur sushi du coin:En pr√©ambule j'ai touj...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2.335660</td>\n",
              "      <td>48.852900</td>\n",
              "      <td>[meilleur sushi coin preambule commande emport...</td>\n",
              "      <td>[5.0, 3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.5</td>\n",
              "      <td>4 rue Affre, 75018 Paris France</td>\n",
              "      <td>Chez Mai</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10965.0</td>\n",
              "      <td>[Super spot pour des plats africains de qualit...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2.355878</td>\n",
              "      <td>48.885218</td>\n",
              "      <td>[super spot plat africain qualite accueil chal...</td>\n",
              "      <td>[4.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>40 rue Saint Honore, 75001 Paris France</td>\n",
              "      <td>Restaurant le Moliere</td>\n",
              "      <td>152.0</td>\n",
              "      <td>2142.0</td>\n",
              "      <td>[Une brasserie classique:Tr√®s bon accueil du p...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨]</td>\n",
              "      <td>[Fran√ßaise, Europ√©enne]</td>\n",
              "      <td>2.344651</td>\n",
              "      <td>48.861170</td>\n",
              "      <td>[brasserie classique bon accueil patron cuisin...</td>\n",
              "      <td>[4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>4.5</td>\n",
              "      <td>17 rue Claude Tillier, 75012 Paris France</td>\n",
              "      <td>Trois Crabes</td>\n",
              "      <td>298.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>[une merveille:service courtois, restaurant bi...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨]</td>\n",
              "      <td>[Asiatique, Vietnamienne, V√©g√©tariens bienvenus]</td>\n",
              "      <td>2.388023</td>\n",
              "      <td>48.848217</td>\n",
              "      <td>[merveill service courtois restaurer bien deco...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 3.0, 5.0, 4.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>4.0</td>\n",
              "      <td>32 Avenue Des Gobelins, 75013 Paris France</td>\n",
              "      <td>Dame Augustine</td>\n",
              "      <td>47.0</td>\n",
              "      <td>2903.0</td>\n",
              "      <td>[Jamais d√©√ßue !:Difficile de choisir tant la c...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨]</td>\n",
              "      <td>[Fran√ßaise]</td>\n",
              "      <td>2.352284</td>\n",
              "      <td>48.835753</td>\n",
              "      <td>[jamais decue difficile choisir carte allechan...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 1.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1 rue Basse Centre Commercial Forum Des Halles...</td>\n",
              "      <td>Brioche Dor√©e Paris 1er Forum des Halles</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5996.0</td>\n",
              "      <td>[D√©√ßues de nos achats au Brioche Dor√©e du Foru...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Fran√ßaise, Restauration rapide]</td>\n",
              "      <td>2.335660</td>\n",
              "      <td>48.852900</td>\n",
              "      <td>[decue achat brioche doree forum halle 02/12/2...</td>\n",
              "      <td>[3.0, 1.0, 4.0, 5.0, 3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>4.0</td>\n",
              "      <td>20 Rue D'Artois, 75008 Paris France</td>\n",
              "      <td>Apicius</td>\n",
              "      <td>278.0</td>\n",
              "      <td>2776.0</td>\n",
              "      <td>[bon mais carte limit√©:Le restaurant Apicius √©...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[‚Ç¨‚Ç¨‚Ç¨‚Ç¨]</td>\n",
              "      <td>[Fran√ßaise, Europ√©enne, V√©g√©tariens bienvenus]</td>\n",
              "      <td>2.307241</td>\n",
              "      <td>48.873339</td>\n",
              "      <td>[bon carte limite restaurant apiciu liste alle...</td>\n",
              "      <td>[4.0, 5.0, 5.0, 3.0, 5.0, 1.0, 5.0, 3.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>4.0</td>\n",
              "      <td>17 Rue Breguet, 75011 Paris France</td>\n",
              "      <td>Louve</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11468.0</td>\n",
              "      <td>[Louve:Mus√©e historique aux longues files, alo...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2.373343</td>\n",
              "      <td>48.857511</td>\n",
              "      <td>[louve musee historique long file faire tour c...</td>\n",
              "      <td>[4.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows √ó 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     average_note                                           location  \\\n",
              "0             4.0           39 Avenue de l'Op√©ra, 75002 Paris France   \n",
              "1             5.0                    54 rue Piat, 75020 Paris France   \n",
              "2             4.0  Avenue des 4 Chemins, 92330 Sceaux, 92330 Pari...   \n",
              "3             4.5                    4 rue Affre, 75018 Paris France   \n",
              "4             4.0            40 rue Saint Honore, 75001 Paris France   \n",
              "..            ...                                                ...   \n",
              "995           4.5          17 rue Claude Tillier, 75012 Paris France   \n",
              "996           4.0         32 Avenue Des Gobelins, 75013 Paris France   \n",
              "997           3.0  1 rue Basse Centre Commercial Forum Des Halles...   \n",
              "998           4.0                20 Rue D'Artois, 75008 Paris France   \n",
              "999           4.0                 17 Rue Breguet, 75011 Paris France   \n",
              "\n",
              "                                         name  number_reviews  ranking  \\\n",
              "0                                      Bar E7             3.0  12392.0   \n",
              "1                          God Bless Broccoli            29.0   4346.0   \n",
              "2                              Sushi Robinson             2.0  12314.0   \n",
              "3                                    Chez Mai             3.0  10965.0   \n",
              "4                       Restaurant le Moliere           152.0   2142.0   \n",
              "..                                        ...             ...      ...   \n",
              "995                              Trois Crabes           298.0    280.0   \n",
              "996                            Dame Augustine            47.0   2903.0   \n",
              "997  Brioche Dor√©e Paris 1er Forum des Halles             5.0   5996.0   \n",
              "998                                   Apicius           278.0   2776.0   \n",
              "999                                     Louve             9.0  11468.0   \n",
              "\n",
              "                                               reviews  \\\n",
              "0    [Bons cocktails et tapas-cuisine imparfaite:Un...   \n",
              "1    [D√©jeuner:Nous avons manger des tr√®s bonne piz...   \n",
              "2    [Meilleur sushi du coin:En pr√©ambule j'ai touj...   \n",
              "3    [Super spot pour des plats africains de qualit...   \n",
              "4    [Une brasserie classique:Tr√®s bon accueil du p...   \n",
              "..                                                 ...   \n",
              "995  [une merveille:service courtois, restaurant bi...   \n",
              "996  [Jamais d√©√ßue !:Difficile de choisir tant la c...   \n",
              "997  [D√©√ßues de nos achats au Brioche Dor√©e du Foru...   \n",
              "998  [bon mais carte limit√©:Le restaurant Apicius √©...   \n",
              "999  [Louve:Mus√©e historique aux longues files, alo...   \n",
              "\n",
              "                                                   url     price  \\\n",
              "0    https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "1    https://www.tripadvisor.fr/Restaurant_Review-g...  [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨]   \n",
              "2    https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "3    https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "4    https://www.tripadvisor.fr/Restaurant_Review-g...  [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨]   \n",
              "..                                                 ...       ...   \n",
              "995  https://www.tripadvisor.fr/Restaurant_Review-g...  [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨]   \n",
              "996  https://www.tripadvisor.fr/Restaurant_Review-g...  [‚Ç¨‚Ç¨-‚Ç¨‚Ç¨‚Ç¨]   \n",
              "997  https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "998  https://www.tripadvisor.fr/Restaurant_Review-g...    [‚Ç¨‚Ç¨‚Ç¨‚Ç¨]   \n",
              "999  https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "\n",
              "                                              cuisine  longitude   latitude  \\\n",
              "0                                                  []   2.333227  48.868499   \n",
              "1           [Italienne, Pizza, V√©g√©tariens bienvenus]   2.383660  48.873115   \n",
              "2                                                  []   2.335660  48.852900   \n",
              "3                                                  []   2.355878  48.885218   \n",
              "4                             [Fran√ßaise, Europ√©enne]   2.344651  48.861170   \n",
              "..                                                ...        ...        ...   \n",
              "995  [Asiatique, Vietnamienne, V√©g√©tariens bienvenus]   2.388023  48.848217   \n",
              "996                                       [Fran√ßaise]   2.352284  48.835753   \n",
              "997                  [Fran√ßaise, Restauration rapide]   2.335660  48.852900   \n",
              "998    [Fran√ßaise, Europ√©enne, V√©g√©tariens bienvenus]   2.307241  48.873339   \n",
              "999                                                []   2.373343  48.857511   \n",
              "\n",
              "                                         clean_reviews  \\\n",
              "0    [bon cocktail tapa cuisine imparfait grand cho...   \n",
              "1    [dejeuner manger bon pizza faire manger super ...   \n",
              "2    [meilleur sushi coin preambule commande emport...   \n",
              "3    [super spot plat africain qualite accueil chal...   \n",
              "4    [brasserie classique bon accueil patron cuisin...   \n",
              "..                                                 ...   \n",
              "995  [merveill service courtois restaurer bien deco...   \n",
              "996  [jamais decue difficile choisir carte allechan...   \n",
              "997  [decue achat brioche doree forum halle 02/12/2...   \n",
              "998  [bon carte limite restaurant apiciu liste alle...   \n",
              "999  [louve musee historique long file faire tour c...   \n",
              "\n",
              "                                               ratings  \n",
              "0                                                [4.0]  \n",
              "1    [5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...  \n",
              "2                                           [5.0, 3.0]  \n",
              "3                                      [4.0, 5.0, 5.0]  \n",
              "4    [4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 1.0, ...  \n",
              "..                                                 ...  \n",
              "995  [5.0, 5.0, 5.0, 5.0, 5.0, 3.0, 5.0, 4.0, 5.0, ...  \n",
              "996  [5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 1.0, 5.0, 5.0, ...  \n",
              "997                          [3.0, 1.0, 4.0, 5.0, 3.0]  \n",
              "998  [4.0, 5.0, 5.0, 3.0, 5.0, 1.0, 5.0, 3.0, 1.0, ...  \n",
              "999                                              [4.0]  \n",
              "\n",
              "[1000 rows x 13 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data.to_json(\"/Users/luciegabagnou/Documents/MOSEF/PYTHON/projet_trip_advisor/sentiment_analysis_tripadvisor/data/clean_data.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.preprocessor.global_processor import ProcessingPipeline\n",
        "ProcessingPipeline(\"data/fetch_data.json\").run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "ERROR:root:KeyboardInterrupt while sending command.                (8 + 8) / 20]\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/socket.py\", line 704, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ProcessingPipeline(\u001b[39m\"\u001b[39;49m\u001b[39mdata/fetch_data.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mrun_pipeline()\n",
            "Cell \u001b[0;32mIn[13], line 104\u001b[0m, in \u001b[0;36mProcessingPipeline.run_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_geocode_location()\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcleaning_text()\n\u001b[0;32m--> 104\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_json(\n\u001b[1;32m    105\u001b[0m     os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mdirname(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjson_filepath), \u001b[39m\"\u001b[39;49m\u001b[39mclean_data.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    106\u001b[0m )\n",
            "Cell \u001b[0;32mIn[13], line 94\u001b[0m, in \u001b[0;36mProcessingPipeline.save_json\u001b[0;34m(self, save_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_json\u001b[39m(\u001b[39mself\u001b[39m, save_path):\n\u001b[1;32m     90\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    save the dataframe in json format\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m    :param save_path: string, the path to save the json file\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49mjson(save_path, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moverwrite\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/pyspark/sql/readwriter.py:846\u001b[0m, in \u001b[0;36mDataFrameWriter.json\u001b[0;34m(self, path, mode, compression, dateFormat, timestampFormat, lineSep, encoding, ignoreNullFields)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode(mode)\n\u001b[1;32m    843\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(\n\u001b[1;32m    844\u001b[0m     compression\u001b[39m=\u001b[39mcompression, dateFormat\u001b[39m=\u001b[39mdateFormat, timestampFormat\u001b[39m=\u001b[39mtimestampFormat,\n\u001b[1;32m    845\u001b[0m     lineSep\u001b[39m=\u001b[39mlineSep, encoding\u001b[39m=\u001b[39mencoding, ignoreNullFields\u001b[39m=\u001b[39mignoreNullFields)\n\u001b[0;32m--> 846\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49mjson(path)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    476\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    477\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    478\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ProcessingPipeline(\"data/fetch_data.json\").run_pipeline()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.16",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "fa67bb4265ed4c5df64e99bc87edf59977441b3ddeff84fb7176f27802866c47"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
