{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S8SleKRtTDoJ"
      },
      "source": [
        "<h1 style=\"text-align: center;\">&nbsp;<img style=\"font-size: 0.9em;\" src=\"https://www.hospitalitynet.org/picture/153007157/travelers-push-tripadvisor-past-1-billion-reviews-opinions.jpg?t=1587981992\" alt=\"\" width=\"300\" height=\"100\" /><span style=\"font-family: tahoma, arial, helvetica, sans-serif; font-size: large;\"><span style=\"font-size: x-large;\"> Preprocessing des données avec PySpark</span></span><span style=\"font-family: tahoma, arial, helvetica, sans-serif; font-size: large;\">&nbsp; &nbsp; &nbsp;&nbsp;</span>&nbsp;<img src=\"https://i0.wp.com/mosefparis1.fr/wp-content/uploads/2022/10/cropped-image-1.png?fit=532%2C540&amp;ssl=1\" alt=\"\" width=\"150\" height=\"150\" />&nbsp;</h1>\n",
        "<p style=\"text-align: center;\">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;de Lucie Gabagnou et Yanis Rehoune</p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ptILyCEMT0ie"
      },
      "source": [
        "Dans ce second notebook, nous effectuons une pipeline de preprocessing des données: Les données brutes qui ont été extraites par Webscraping ne sont pas forcément dans le format attendu. Il faut ainsi nettoyer les données et extraire des features pertinents.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jYKefruS5iI9"
      },
      "source": [
        "# Processing avec PySpark\n",
        "Dans cette partie, nous réalisons le processing de nos données: on nettoie (le texte particulièrement) et éventuellement créer de nouveaux features à partir de la base brute récoltée. Ici, il faut s'assurer que les types soient les bons, que le texte soit exploitable pour le NLP, et que tous les features soient exploitables (typiquement l'adresse doit devenir un ensemble de coordonnées géographiques..).\n",
        "\n",
        "\n",
        "\n",
        "\n",
        " Dans notre cas, Pyspark s'avère pratique pour exécuter facilement des fonctions sur un nombre de lignes  important. \n",
        "A l'issue de cette étape, les données seront prêtes pour l'analyse exploratoire et le ML.\n",
        "Remarque: il n'y a pas d'étapes intermédiaires pour voir les données car on évite d'utiliser les fonctions .show() qui puisent dans la mémoire vive et sont longues.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "REMARQUE: \n",
        "- Si vous utilisez PySpark en local, assurez-vous d'avoir bien installé PySpark (cf README)\n",
        "- Si vous utilisez PySpark sur google colab, assurez-vous d'avoir un dossier sur le drive comportant le projet!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Dj9e4kU7vmt"
      },
      "source": [
        "#### Installation de l'environnement"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'/Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/pyspark'"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import findspark\n",
        "import os\n",
        "findspark.init()\n",
        "findspark.find()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "On définit un chemin actuel à la racine du projet pour accéder facilement aux contenus des autres modules:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "x0dR8WA078lG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Current path /Users/luciegabagnou/Documents/MOSEF/PYTHON/projet_trip_advisor/sentiment_analysis_tripadvisor\n"
          ]
        }
      ],
      "source": [
        "current_path=os.path.dirname(os.getcwd())\n",
        "os.chdir(current_path)\n",
        "print(\"Current path\",os.getcwd())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sJNrwNHW1ATf"
      },
      "source": [
        "### Création d'un SparkDataFrame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "6ykjaJ3t8MkF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: selenium in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 1)) (4.8.0)\n",
            "Requirement already satisfied: pyspark in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 2)) (3.2.1)\n",
            "Requirement already satisfied: findspark in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 3)) (2.0.1)\n",
            "Requirement already satisfied: requests in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 4)) (2.28.2)\n",
            "Requirement already satisfied: mysqlclient in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 5)) (2.1.1)\n",
            "Requirement already satisfied: unidecode in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 6)) (1.3.6)\n",
            "Requirement already satisfied: scrapy in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 7)) (2.7.1)\n",
            "Requirement already satisfied: bs4 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 8)) (0.0.1)\n",
            "Requirement already satisfied: undetected-chromedriver in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 9)) (3.2.1)\n",
            "Requirement already satisfied: spacy in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 10)) (3.5.0)\n",
            "Requirement already satisfied: matplotlib in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 11)) (3.6.3)\n",
            "Requirement already satisfied: pandas in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 12)) (1.5.3)\n",
            "Requirement already satisfied: python-dotenv in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 13)) (0.21.1)\n",
            "Requirement already satisfied: plotly in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 14)) (5.2.1)\n",
            "Requirement already satisfied: scikit-learn in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 15)) (1.2.1)\n",
            "Requirement already satisfied: wordcloud in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 16)) (1.8.2.2)\n",
            "Requirement already satisfied: textblob in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 17)) (0.17.1)\n",
            "Requirement already satisfied: geopy in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from -r requirements.txt (line 18)) (2.3.0)\n",
            "Requirement already satisfied: trio~=0.17 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 1)) (0.22.0)\n",
            "Requirement already satisfied: certifi>=2021.10.8 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 1)) (2022.12.7)\n",
            "Requirement already satisfied: urllib3[socks]~=1.26 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 1)) (1.26.14)\n",
            "Requirement already satisfied: trio-websocket~=0.9 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from selenium->-r requirements.txt (line 1)) (0.9.2)\n",
            "Requirement already satisfied: py4j==0.10.9.3 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from pyspark->-r requirements.txt (line 2)) (0.10.9.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from requests->-r requirements.txt (line 4)) (2.1.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from requests->-r requirements.txt (line 4)) (3.4)\n",
            "Requirement already satisfied: packaging in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (21.3)\n",
            "Requirement already satisfied: cssselect>=0.9.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (1.2.0)\n",
            "Requirement already satisfied: zope.interface>=5.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (5.5.2)\n",
            "Requirement already satisfied: protego>=0.1.15 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (0.2.1)\n",
            "Requirement already satisfied: tldextract in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (3.4.0)\n",
            "Requirement already satisfied: queuelib>=1.4.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (1.6.2)\n",
            "Requirement already satisfied: w3lib>=1.17.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (2.1.1)\n",
            "Requirement already satisfied: itemadapter>=0.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: cryptography>=3.3 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (38.0.4)\n",
            "Requirement already satisfied: lxml>=4.3.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (4.9.2)\n",
            "Requirement already satisfied: setuptools in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (65.6.3)\n",
            "Requirement already satisfied: parsel>=1.5.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (1.7.0)\n",
            "Requirement already satisfied: service-identity>=18.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (21.1.0)\n",
            "Requirement already satisfied: PyDispatcher>=2.0.5 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (2.0.6)\n",
            "Requirement already satisfied: pyOpenSSL>=21.0.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (23.0.0)\n",
            "Requirement already satisfied: Twisted>=18.9.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (22.10.0)\n",
            "Requirement already satisfied: itemloaders>=1.0.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scrapy->-r requirements.txt (line 7)) (1.0.6)\n",
            "Requirement already satisfied: beautifulsoup4 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from bs4->-r requirements.txt (line 8)) (4.11.1)\n",
            "Requirement already satisfied: websockets in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from undetected-chromedriver->-r requirements.txt (line 9)) (10.4)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (4.64.1)\n",
            "Requirement already satisfied: pathy>=0.10.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (0.10.1)\n",
            "Requirement already satisfied: jinja2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (3.1.2)\n",
            "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (8.1.7)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.1.1)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (3.0.8)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (3.0.12)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.15.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.23.5)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (2.0.8)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (3.3.0)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.0.4)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (2.4.5)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.10.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (6.3.0)\n",
            "Requirement already satisfied: typer<0.8.0,>=0.3.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (0.7.0)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from spacy->-r requirements.txt (line 10)) (1.0.9)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (4.38.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (2.8.2)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (1.4.4)\n",
            "Requirement already satisfied: pyparsing>=2.2.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (3.0.9)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (1.0.7)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (9.4.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from matplotlib->-r requirements.txt (line 11)) (0.11.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from pandas->-r requirements.txt (line 12)) (2022.7.1)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from plotly->-r requirements.txt (line 14)) (8.1.0)\n",
            "Requirement already satisfied: six in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from plotly->-r requirements.txt (line 14)) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 15)) (1.2.0)\n",
            "Requirement already satisfied: scipy>=1.3.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 15)) (1.10.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from scikit-learn->-r requirements.txt (line 15)) (3.1.0)\n",
            "Requirement already satisfied: nltk>=3.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from textblob->-r requirements.txt (line 17)) (3.8.1)\n",
            "Requirement already satisfied: geographiclib<3,>=1.52 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from geopy->-r requirements.txt (line 18)) (2.0)\n",
            "Requirement already satisfied: cffi>=1.12 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from cryptography>=3.3->scrapy->-r requirements.txt (line 7)) (1.15.1)\n",
            "Requirement already satisfied: jmespath>=0.9.5 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from itemloaders>=1.0.1->scrapy->-r requirements.txt (line 7)) (1.0.1)\n",
            "Requirement already satisfied: click in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from nltk>=3.1->textblob->-r requirements.txt (line 17)) (8.1.3)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from nltk>=3.1->textblob->-r requirements.txt (line 17)) (2022.10.31)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy->-r requirements.txt (line 10)) (4.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy->-r requirements.txt (line 7)) (22.2.0)\n",
            "Requirement already satisfied: pyasn1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy->-r requirements.txt (line 7)) (0.4.8)\n",
            "Requirement already satisfied: pyasn1-modules in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from service-identity>=18.1.0->scrapy->-r requirements.txt (line 7)) (0.2.8)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 10)) (0.7.9)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from thinc<8.2.0,>=8.1.0->spacy->-r requirements.txt (line 10)) (0.0.4)\n",
            "Requirement already satisfied: outcome in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: sniffio in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.1.0)\n",
            "Requirement already satisfied: sortedcontainers in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (2.4.0)\n",
            "Requirement already satisfied: async-generator>=1.9 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio~=0.17->selenium->-r requirements.txt (line 1)) (1.10)\n",
            "Requirement already satisfied: wsproto>=0.14 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (1.2.0)\n",
            "Requirement already satisfied: incremental>=21.3.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy->-r requirements.txt (line 7)) (22.10.0)\n",
            "Requirement already satisfied: constantly>=15.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy->-r requirements.txt (line 7)) (15.1.0)\n",
            "Requirement already satisfied: hyperlink>=17.1.1 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy->-r requirements.txt (line 7)) (21.0.0)\n",
            "Requirement already satisfied: Automat>=0.8.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from Twisted>=18.9.0->scrapy->-r requirements.txt (line 7)) (22.10.0)\n",
            "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from urllib3[socks]~=1.26->selenium->-r requirements.txt (line 1)) (1.7.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from beautifulsoup4->bs4->-r requirements.txt (line 8)) (2.3.2.post1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from jinja2->spacy->-r requirements.txt (line 10)) (2.1.2)\n",
            "Requirement already satisfied: filelock>=3.0.8 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from tldextract->scrapy->-r requirements.txt (line 7)) (3.9.0)\n",
            "Requirement already satisfied: requests-file>=1.4 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from tldextract->scrapy->-r requirements.txt (line 7)) (1.5.1)\n",
            "Requirement already satisfied: pycparser in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from cffi>=1.12->cryptography>=3.3->scrapy->-r requirements.txt (line 7)) (2.21)\n",
            "Requirement already satisfied: h11<1,>=0.9.0 in /Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium->-r requirements.txt (line 1)) (0.14.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt\n",
        "#!python -m spacy download fr_core_news_md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-qjJ-2Pq1ATg"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "from pyspark import  HiveContext , SparkContext\n",
        "from pyspark.sql.types import StructType, StructField, StringType, IntegerType, ArrayType, DoubleType\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, udf\n",
        "import re\n",
        "from scripts.utils import get_digits\n",
        "from scripts.preprocessor.global_processor import geocode_address,separate_price_and_cuisine\n",
        "from scripts.preprocessor.text_processor import clean_text_sentiment_analysis\n",
        "import nltk\n",
        "import spacy\n",
        "from unidecode import unidecode\n",
        "from nltk.corpus import stopwords\n",
        "import spacy\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1VWBsExlBveq"
      },
      "source": [
        "Dans un premier temps, on créer une session Spark, celle sur laquelle on va load le dataframe et effectuer nos modifications. Dans le notebook, on load un DataFrame, mais dans la partie développement, on exectuera cela sur la base MySQL. "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "id": "8iBOMHSL1ATj"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------------+--------------------+--------------+--------------------+---------+--------------------+--------------------+\n",
            "|average_note|            location|                name|number_reviews|  price_and_cuisines|  ranking|             reviews|                 url|\n",
            "+------------+--------------------+--------------------+--------------+--------------------+---------+--------------------+--------------------+\n",
            "|         4,5|149 boulevard Vol...|        Cafe Leopard|            97|[€€-€€€, Français...|    Nº 39|[Café Leopard, al...|https://www.tripa...|\n",
            "|         4,0|68 Rue de Grenell...|       Cuillier Café|             7|           [€, Café]|   Nº 708|[Bon petit goûter...|https://www.tripa...|\n",
            "|         4,0|40 rue Gregoire d...|          Oenosteria|           138|[€€-€€€, Italienn...| Nº 2 485|[A éviter absolum...|https://www.tripa...|\n",
            "|         4,5|9 Rue Joseph de M...|           La Bossue|           480|[€€-€€€, Français...|   Nº 174|[Superbe expérien...|https://www.tripa...|\n",
            "|         4,0|7 Rue du Faubourg...|            Baranaan|           256|[€€-€€€, Indienne...| Nº 1 742|[Concept sympa:Pe...|https://www.tripa...|\n",
            "|         3,5|108 Rue de la Roq...|        La Fee Verte|           307|[€€-€€€, Français...|   Nº 131|[Super:Superbe ex...|https://www.tripa...|\n",
            "|         4,5|4 Avenue Carnot, ...|        Le Vin Coeur|           675|[€€-€€€, Français...|   Nº 261|[Très bonne soiré...|https://www.tripa...|\n",
            "|         5,0|210 Rue Saint-Mau...|         Leo Bistrot|             1|                  []|Nº 11 602|                  []|https://www.tripa...|\n",
            "|         5,0|80 boulevard Rasp...|           Foodelice|            13|[€, Café, Restaur...|   Nº 423|[Très bonne adres...|https://www.tripa...|\n",
            "|         3,5|16 Place des Abbe...|Une Glace à Paris...|            10|   [€€€€, Française]| Nº 5 854|[Service horrible...|https://www.tripa...|\n",
            "|         5,0|32 avenue louis p...|FOOD FACTORY Bagneux|             1|                  []|Nº 12 301|[Commande Uber ea...|https://www.tripa...|\n",
            "|         3,0|68 rue Saint Deni...|  Hall's Beer Tavern|           107|[€€-€€€, Français...|Nº 13 190|[Un service au to...|https://www.tripa...|\n",
            "|         4,5|36 boulevard Dide...|Cafe Minute Papillon|            69| [€€-€€€, Française]| Nº 1 899|[Fort sympathique...|https://www.tripa...|\n",
            "|         4,0|55 Rue Montmartre...|     Pizz'aria Paris|             1|     [€€-€€€, Pizza]|   Nº 667|[Très bonnes pizz...|https://www.tripa...|\n",
            "|         3,0|271 avenue Daumes...|Pizzeria Villa Ro...|            87|[€€-€€€, Italienn...| Nº 3 423|[Un restaurant qu...|https://www.tripa...|\n",
            "|         4,5|9 Place de l’Adju...|         Grill House|             3| [€€-€€€, Française]| Nº 5 039|[NE PAS SE FIER Q...|https://www.tripa...|\n",
            "|         4,5|110 boulevard de ...|Le Diplomate Pari...|            93|[€€-€€€, Français...| Nº 1 642|[Adresse à reteni...|https://www.tripa...|\n",
            "|         4,5|71 rue des Gravil...|          Ai's Bento|            29|[€€-€€€, Chinoise...|   Nº 593|[Cuisine asiatiqu...|https://www.tripa...|\n",
            "|         3,5|42 rue Mazarine, ...|  Le Bistrot Mazarin|           283|[€€-€€€, Français...| Nº 4 934|[Une excellente b...|https://www.tripa...|\n",
            "|         4,0|35 rue de Rivoli,...|               Bayan|            28|[€€-€€€, Chinoise...| Nº 6 106|[Excellent 👌:Bon...|https://www.tripa...|\n",
            "+------------+--------------------+--------------------+--------------+--------------------+---------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ],
      "source": [
        "spark = SparkSession.builder.appName(\"Load JSON\").getOrCreate()\n",
        "df = spark.read.option(\"multiline\",\"true\").json(\"data/fetch_data.json\")\n",
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dv8OyTtdCY5i"
      },
      "source": [
        "Dans un premier temps, on s'assure que les types soient corrects:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "9rcNN6f6BAX5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- average_note: string (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- number_reviews: string (nullable = true)\n",
            " |-- price_and_cuisines: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ranking: string (nullable = true)\n",
            " |-- reviews: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- url: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sdkxSDOhDU7T"
      },
      "source": [
        "On voit que \"average note\" est en string alors qu'il doit s'agir de nombres décimaux, de même pour le nombre de reviews, le classement (ranking).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XzjRAkoQDX6P"
      },
      "source": [
        "#### Type \n",
        "On corrige les types qui posaient problèmes précèdemment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "id": "1Ssfw0u_H4EH"
      },
      "outputs": [],
      "source": [
        "# Création d'une fonction définie par utilisateur (udf). On a repris la fonction get_digits disponibles dans les utils\n",
        "# Application sur la colonne des classements pour récupérer les chiffres/nombres de la chaîne de caractères n°1 => 1\n",
        "# Apply UDF to the column \"tripadvisor rank\"\n",
        "from pyspark.sql.functions import col, lit, regexp_replace\n",
        "get_digits_udf = udf(get_digits, DoubleType())\n",
        "df = df.withColumn(\"average_note\", regexp_replace(col(\"average_note\"), \",\", \".\"))\n",
        "df = df.withColumn(\"ranking\", get_digits_udf(df[\"ranking\"]))\n",
        "df = df.withColumn(\"average_note\", get_digits_udf(df[\"average_note\"]))\n",
        "df = df.withColumn(\"number_reviews\", get_digits_udf(df[\"number_reviews\"]))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "99aLa4t19Gic"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "root\n",
            " |-- average_note: double (nullable = true)\n",
            " |-- location: string (nullable = true)\n",
            " |-- name: string (nullable = true)\n",
            " |-- number_reviews: double (nullable = true)\n",
            " |-- price_and_cuisines: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- ranking: double (nullable = true)\n",
            " |-- reviews: array (nullable = true)\n",
            " |    |-- element: string (containsNull = true)\n",
            " |-- url: string (nullable = true)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "df.printSchema()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "8CgKloJ24L-7"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[Stage 32:>                                                         (0 + 1) / 1]\r"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------------------+\n",
            "|average_note|            location|                name|number_reviews|  price_and_cuisines|ranking|             reviews|                 url|\n",
            "+------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------------------+\n",
            "|         4.5|149 boulevard Vol...|        Cafe Leopard|          97.0|[€€-€€€, Français...|   39.0|[Café Leopard, al...|https://www.tripa...|\n",
            "|         4.0|68 Rue de Grenell...|       Cuillier Café|           7.0|           [€, Café]|  708.0|[Bon petit goûter...|https://www.tripa...|\n",
            "|         4.0|40 rue Gregoire d...|          Oenosteria|         138.0|[€€-€€€, Italienn...| 2485.0|[A éviter absolum...|https://www.tripa...|\n",
            "|         4.5|9 Rue Joseph de M...|           La Bossue|         480.0|[€€-€€€, Français...|  174.0|[Superbe expérien...|https://www.tripa...|\n",
            "|         4.0|7 Rue du Faubourg...|            Baranaan|         256.0|[€€-€€€, Indienne...| 1742.0|[Concept sympa:Pe...|https://www.tripa...|\n",
            "|         3.5|108 Rue de la Roq...|        La Fee Verte|         307.0|[€€-€€€, Français...|  131.0|[Super:Superbe ex...|https://www.tripa...|\n",
            "|         4.5|4 Avenue Carnot, ...|        Le Vin Coeur|         675.0|[€€-€€€, Français...|  261.0|[Très bonne soiré...|https://www.tripa...|\n",
            "|         5.0|210 Rue Saint-Mau...|         Leo Bistrot|           1.0|                  []|11602.0|                  []|https://www.tripa...|\n",
            "|         5.0|80 boulevard Rasp...|           Foodelice|          13.0|[€, Café, Restaur...|  423.0|[Très bonne adres...|https://www.tripa...|\n",
            "|         3.5|16 Place des Abbe...|Une Glace à Paris...|          10.0|   [€€€€, Française]| 5854.0|[Service horrible...|https://www.tripa...|\n",
            "|         5.0|32 avenue louis p...|FOOD FACTORY Bagneux|           1.0|                  []|12301.0|[Commande Uber ea...|https://www.tripa...|\n",
            "|         3.0|68 rue Saint Deni...|  Hall's Beer Tavern|         107.0|[€€-€€€, Français...|13190.0|[Un service au to...|https://www.tripa...|\n",
            "|         4.5|36 boulevard Dide...|Cafe Minute Papillon|          69.0| [€€-€€€, Française]| 1899.0|[Fort sympathique...|https://www.tripa...|\n",
            "|         4.0|55 Rue Montmartre...|     Pizz'aria Paris|           1.0|     [€€-€€€, Pizza]|  667.0|[Très bonnes pizz...|https://www.tripa...|\n",
            "|         3.0|271 avenue Daumes...|Pizzeria Villa Ro...|          87.0|[€€-€€€, Italienn...| 3423.0|[Un restaurant qu...|https://www.tripa...|\n",
            "|         4.5|9 Place de l’Adju...|         Grill House|           3.0| [€€-€€€, Française]| 5039.0|[NE PAS SE FIER Q...|https://www.tripa...|\n",
            "|         4.5|110 boulevard de ...|Le Diplomate Pari...|          93.0|[€€-€€€, Français...| 1642.0|[Adresse à reteni...|https://www.tripa...|\n",
            "|         4.5|71 rue des Gravil...|          Ai's Bento|          29.0|[€€-€€€, Chinoise...|  593.0|[Cuisine asiatiqu...|https://www.tripa...|\n",
            "|         3.5|42 rue Mazarine, ...|  Le Bistrot Mazarin|         283.0|[€€-€€€, Français...| 4934.0|[Une excellente b...|https://www.tripa...|\n",
            "|         4.0|35 rue de Rivoli,...|               Bayan|          28.0|[€€-€€€, Chinoise...| 6106.0|[Excellent 👌:Bon...|https://www.tripa...|\n",
            "+------------+--------------------+--------------------+--------------+--------------------+-------+--------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "df.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aftIph6tIuoW"
      },
      "source": [
        "Les types ont bien été corrigés."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Traitement des valeurs manquantes\n",
        "On traite les valeurs manquantes sur les variables numériques, qui sont celles pouvant ne pas être remplies (pas de reviews => pas de nb reviews, pas de note moyenne)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = df.na.fill({\n",
        "    \"average_note\": 0,\n",
        "    \"ranking\": 0,\n",
        "    \"number_reviews\": 0\n",
        "})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQlRI4bqIxuR"
      },
      "source": [
        "### Feature engineering:\n",
        "- On va séparer le contenu de la colonne \"price and cuisines\", qui regroupe le prix et les types de cuisine. Nous ne l'avons pas fait lors du webscrapping sachant qu'il n'était pas évident de séparer le contenu: \n",
        "- Géolocalisation: on veut récupérer les coordonnées géographiques pour l'appli.."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWr35HyQJUZP"
      },
      "source": [
        "##### Price and cuisines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNOrakBAJZEy"
      },
      "source": [
        "En effet, on voit qu'il n'est pas évident de trouver une règle simple de séparation car le nombre d'élements n'est pas le même selon les restaurants (parfois aucune information, parfois 4, parfois prix, parfois non, etc..):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "5yNxU5R_J7Ij"
      },
      "outputs": [],
      "source": [
        "\n",
        "# On impose un schéma pour faire en sorte d'avoir le format final souhaité, à savoir des listes/arrays de chaîne de caractères\n",
        "udf_separate_price_and_cuisine = udf(separate_price_and_cuisine, StructType([\n",
        "    StructField(\"price\", ArrayType(StringType())),\n",
        "    StructField(\"cuisine\", ArrayType(StringType()))\n",
        "])) # On renseigne ce schéma dans l' udf\n",
        "\n",
        "#On applique les fonctions\n",
        "df = df.withColumn(\"price\", udf_separate_price_and_cuisine(\"price_and_cuisines\").price) \n",
        "df = df.withColumn(\"cuisine\", udf_separate_price_and_cuisine(\"price_and_cuisines\").cuisine)\n",
        "df = df.drop(*[\"price_and_cuisines\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aqd0VsPkLZ7N"
      },
      "source": [
        "##### Localisation\n",
        "On utilise le package geopy pour convertir nos adresses en coordonnées GPS: On créée une colonne pour la longitude et une pour la latitude."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "skSPkq5VC-5c"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "from geopy.geocoders import Nominatim\n",
        "from pyspark.sql.functions import udf,mean\n",
        "from pyspark.sql.types import StructType, StructField, DoubleType\n",
        "from scripts.preprocessor.global_processor import geocode_address\n",
        "\n",
        "geocode_udf = udf(\n",
        "            geocode_address,\n",
        "            returnType = StructType([\n",
        "    StructField(\"latitude\", DoubleType()),\n",
        "    StructField(\"longitude\",DoubleType())]))\n",
        "\n",
        "df = df.repartition(20) \n",
        "df = df.withColumn(\"longitude\", geocode_udf(\"location\").longitude)\n",
        "df = df.withColumn(\"latitude\", geocode_udf(\"location\").latitude)\n",
        "\n",
        "#On fill par la moyenne\n",
        "\n",
        "avg_longitude = df.agg(mean(df[\"longitude\"])).first()[0]\n",
        "avg_latitude = df.agg(mean(df[\"latitude\"])).first()[0]\n",
        "df = df.fillna(avg_longitude, subset=\"longitude\")\n",
        "df = df.fillna(avg_latitude, subset=\"latitude\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZYc6hi_zdhhl"
      },
      "source": [
        "##### Commentaires\n",
        "Pour les commentaires, on applique notre pipeline NLP qui a pour objectif de nettoyer un ensemble de commentaires en vue d'une analyse de sentiment. Elle effectue plusieurs opérations de nettoyage, telles que la conversion en minuscules, la suppression de caractères spéciaux et de chiffres, la suppression de mots-clés, la lemmatisation et la suppression d'entités nommées. Elle utilise la bibliothèque spaCy pour la lemmatisation et la suppression d'entités nommées. Enfin, la fonction retourne une liste de commentaires nettoyés. De plus, elle récupère les notes associées aux commentaires dans une autre colonne pour compléter cette analyse."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "YDhSp_oYivGi"
      },
      "outputs": [],
      "source": [
        "udf_text_cleaning = udf(clean_text_sentiment_analysis, StructType([\n",
        "    StructField(\"reviews\", ArrayType(StringType())),\n",
        "    StructField(\"ratings\", ArrayType(StringType()))]))\n",
        "\n",
        "\n",
        "df=df.withColumn(\"clean_reviews\", udf_text_cleaning(\"reviews\").reviews)\n",
        "df=df.withColumn(\"ratings\", udf_text_cleaning(\"reviews\").ratings)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Conversion des données\n",
        "On passe par Pandas car cela nous permet d'éviter des problèmes de conversion (les méthodes df.write... ne sont pas particulièrement adapté à nos données)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "6z7vu6LyOrlK"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to                        (0 + 1) / 1]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "                                                                                \r"
          ]
        }
      ],
      "source": [
        "clean_data=df.toPandas() # Environ 10 min"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>average_note</th>\n",
              "      <th>location</th>\n",
              "      <th>name</th>\n",
              "      <th>number_reviews</th>\n",
              "      <th>ranking</th>\n",
              "      <th>reviews</th>\n",
              "      <th>url</th>\n",
              "      <th>price</th>\n",
              "      <th>cuisine</th>\n",
              "      <th>longitude</th>\n",
              "      <th>latitude</th>\n",
              "      <th>clean_reviews</th>\n",
              "      <th>ratings</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>4.0</td>\n",
              "      <td>39 Avenue de l'Opéra, 75002 Paris France</td>\n",
              "      <td>Bar E7</td>\n",
              "      <td>3.0</td>\n",
              "      <td>12392.0</td>\n",
              "      <td>[Bons cocktails et tapas-cuisine imparfaite:Un...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2.333227</td>\n",
              "      <td>48.868499</td>\n",
              "      <td>[bon cocktail tapa cuisine imparfait grand cho...</td>\n",
              "      <td>[4.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5.0</td>\n",
              "      <td>54 rue Piat, 75020 Paris France</td>\n",
              "      <td>God Bless Broccoli</td>\n",
              "      <td>29.0</td>\n",
              "      <td>4346.0</td>\n",
              "      <td>[Déjeuner:Nous avons manger des très bonne piz...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[€€-€€€]</td>\n",
              "      <td>[Italienne, Pizza, Végétariens bienvenus]</td>\n",
              "      <td>2.383660</td>\n",
              "      <td>48.873115</td>\n",
              "      <td>[dejeuner manger bon pizza faire manger super ...</td>\n",
              "      <td>[5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>4.0</td>\n",
              "      <td>Avenue des 4 Chemins, 92330 Sceaux, 92330 Pari...</td>\n",
              "      <td>Sushi Robinson</td>\n",
              "      <td>2.0</td>\n",
              "      <td>12314.0</td>\n",
              "      <td>[Meilleur sushi du coin:En préambule j'ai touj...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2.335660</td>\n",
              "      <td>48.852900</td>\n",
              "      <td>[meilleur sushi coin preambule commande emport...</td>\n",
              "      <td>[5.0, 3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>4.5</td>\n",
              "      <td>4 rue Affre, 75018 Paris France</td>\n",
              "      <td>Chez Mai</td>\n",
              "      <td>3.0</td>\n",
              "      <td>10965.0</td>\n",
              "      <td>[Super spot pour des plats africains de qualit...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2.355878</td>\n",
              "      <td>48.885218</td>\n",
              "      <td>[super spot plat africain qualite accueil chal...</td>\n",
              "      <td>[4.0, 5.0, 5.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4.0</td>\n",
              "      <td>40 rue Saint Honore, 75001 Paris France</td>\n",
              "      <td>Restaurant le Moliere</td>\n",
              "      <td>152.0</td>\n",
              "      <td>2142.0</td>\n",
              "      <td>[Une brasserie classique:Très bon accueil du p...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[€€-€€€]</td>\n",
              "      <td>[Française, Européenne]</td>\n",
              "      <td>2.344651</td>\n",
              "      <td>48.861170</td>\n",
              "      <td>[brasserie classique bon accueil patron cuisin...</td>\n",
              "      <td>[4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>4.5</td>\n",
              "      <td>17 rue Claude Tillier, 75012 Paris France</td>\n",
              "      <td>Trois Crabes</td>\n",
              "      <td>298.0</td>\n",
              "      <td>280.0</td>\n",
              "      <td>[une merveille:service courtois, restaurant bi...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[€€-€€€]</td>\n",
              "      <td>[Asiatique, Vietnamienne, Végétariens bienvenus]</td>\n",
              "      <td>2.388023</td>\n",
              "      <td>48.848217</td>\n",
              "      <td>[merveill service courtois restaurer bien deco...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 5.0, 5.0, 3.0, 5.0, 4.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>4.0</td>\n",
              "      <td>32 Avenue Des Gobelins, 75013 Paris France</td>\n",
              "      <td>Dame Augustine</td>\n",
              "      <td>47.0</td>\n",
              "      <td>2903.0</td>\n",
              "      <td>[Jamais déçue !:Difficile de choisir tant la c...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[€€-€€€]</td>\n",
              "      <td>[Française]</td>\n",
              "      <td>2.352284</td>\n",
              "      <td>48.835753</td>\n",
              "      <td>[jamais decue difficile choisir carte allechan...</td>\n",
              "      <td>[5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 1.0, 5.0, 5.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>3.0</td>\n",
              "      <td>1 rue Basse Centre Commercial Forum Des Halles...</td>\n",
              "      <td>Brioche Dorée Paris 1er Forum des Halles</td>\n",
              "      <td>5.0</td>\n",
              "      <td>5996.0</td>\n",
              "      <td>[Déçues de nos achats au Brioche Dorée du Foru...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[Française, Restauration rapide]</td>\n",
              "      <td>2.335660</td>\n",
              "      <td>48.852900</td>\n",
              "      <td>[decue achat brioche doree forum halle 02/12/2...</td>\n",
              "      <td>[3.0, 1.0, 4.0, 5.0, 3.0]</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>4.0</td>\n",
              "      <td>20 Rue D'Artois, 75008 Paris France</td>\n",
              "      <td>Apicius</td>\n",
              "      <td>278.0</td>\n",
              "      <td>2776.0</td>\n",
              "      <td>[bon mais carte limité:Le restaurant Apicius é...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[€€€€]</td>\n",
              "      <td>[Française, Européenne, Végétariens bienvenus]</td>\n",
              "      <td>2.307241</td>\n",
              "      <td>48.873339</td>\n",
              "      <td>[bon carte limite restaurant apiciu liste alle...</td>\n",
              "      <td>[4.0, 5.0, 5.0, 3.0, 5.0, 1.0, 5.0, 3.0, 1.0, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>4.0</td>\n",
              "      <td>17 Rue Breguet, 75011 Paris France</td>\n",
              "      <td>Louve</td>\n",
              "      <td>9.0</td>\n",
              "      <td>11468.0</td>\n",
              "      <td>[Louve:Musée historique aux longues files, alo...</td>\n",
              "      <td>https://www.tripadvisor.fr/Restaurant_Review-g...</td>\n",
              "      <td>[]</td>\n",
              "      <td>[]</td>\n",
              "      <td>2.373343</td>\n",
              "      <td>48.857511</td>\n",
              "      <td>[louve musee historique long file faire tour c...</td>\n",
              "      <td>[4.0]</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1000 rows × 13 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     average_note                                           location  \\\n",
              "0             4.0           39 Avenue de l'Opéra, 75002 Paris France   \n",
              "1             5.0                    54 rue Piat, 75020 Paris France   \n",
              "2             4.0  Avenue des 4 Chemins, 92330 Sceaux, 92330 Pari...   \n",
              "3             4.5                    4 rue Affre, 75018 Paris France   \n",
              "4             4.0            40 rue Saint Honore, 75001 Paris France   \n",
              "..            ...                                                ...   \n",
              "995           4.5          17 rue Claude Tillier, 75012 Paris France   \n",
              "996           4.0         32 Avenue Des Gobelins, 75013 Paris France   \n",
              "997           3.0  1 rue Basse Centre Commercial Forum Des Halles...   \n",
              "998           4.0                20 Rue D'Artois, 75008 Paris France   \n",
              "999           4.0                 17 Rue Breguet, 75011 Paris France   \n",
              "\n",
              "                                         name  number_reviews  ranking  \\\n",
              "0                                      Bar E7             3.0  12392.0   \n",
              "1                          God Bless Broccoli            29.0   4346.0   \n",
              "2                              Sushi Robinson             2.0  12314.0   \n",
              "3                                    Chez Mai             3.0  10965.0   \n",
              "4                       Restaurant le Moliere           152.0   2142.0   \n",
              "..                                        ...             ...      ...   \n",
              "995                              Trois Crabes           298.0    280.0   \n",
              "996                            Dame Augustine            47.0   2903.0   \n",
              "997  Brioche Dorée Paris 1er Forum des Halles             5.0   5996.0   \n",
              "998                                   Apicius           278.0   2776.0   \n",
              "999                                     Louve             9.0  11468.0   \n",
              "\n",
              "                                               reviews  \\\n",
              "0    [Bons cocktails et tapas-cuisine imparfaite:Un...   \n",
              "1    [Déjeuner:Nous avons manger des très bonne piz...   \n",
              "2    [Meilleur sushi du coin:En préambule j'ai touj...   \n",
              "3    [Super spot pour des plats africains de qualit...   \n",
              "4    [Une brasserie classique:Très bon accueil du p...   \n",
              "..                                                 ...   \n",
              "995  [une merveille:service courtois, restaurant bi...   \n",
              "996  [Jamais déçue !:Difficile de choisir tant la c...   \n",
              "997  [Déçues de nos achats au Brioche Dorée du Foru...   \n",
              "998  [bon mais carte limité:Le restaurant Apicius é...   \n",
              "999  [Louve:Musée historique aux longues files, alo...   \n",
              "\n",
              "                                                   url     price  \\\n",
              "0    https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "1    https://www.tripadvisor.fr/Restaurant_Review-g...  [€€-€€€]   \n",
              "2    https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "3    https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "4    https://www.tripadvisor.fr/Restaurant_Review-g...  [€€-€€€]   \n",
              "..                                                 ...       ...   \n",
              "995  https://www.tripadvisor.fr/Restaurant_Review-g...  [€€-€€€]   \n",
              "996  https://www.tripadvisor.fr/Restaurant_Review-g...  [€€-€€€]   \n",
              "997  https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "998  https://www.tripadvisor.fr/Restaurant_Review-g...    [€€€€]   \n",
              "999  https://www.tripadvisor.fr/Restaurant_Review-g...        []   \n",
              "\n",
              "                                              cuisine  longitude   latitude  \\\n",
              "0                                                  []   2.333227  48.868499   \n",
              "1           [Italienne, Pizza, Végétariens bienvenus]   2.383660  48.873115   \n",
              "2                                                  []   2.335660  48.852900   \n",
              "3                                                  []   2.355878  48.885218   \n",
              "4                             [Française, Européenne]   2.344651  48.861170   \n",
              "..                                                ...        ...        ...   \n",
              "995  [Asiatique, Vietnamienne, Végétariens bienvenus]   2.388023  48.848217   \n",
              "996                                       [Française]   2.352284  48.835753   \n",
              "997                  [Française, Restauration rapide]   2.335660  48.852900   \n",
              "998    [Française, Européenne, Végétariens bienvenus]   2.307241  48.873339   \n",
              "999                                                []   2.373343  48.857511   \n",
              "\n",
              "                                         clean_reviews  \\\n",
              "0    [bon cocktail tapa cuisine imparfait grand cho...   \n",
              "1    [dejeuner manger bon pizza faire manger super ...   \n",
              "2    [meilleur sushi coin preambule commande emport...   \n",
              "3    [super spot plat africain qualite accueil chal...   \n",
              "4    [brasserie classique bon accueil patron cuisin...   \n",
              "..                                                 ...   \n",
              "995  [merveill service courtois restaurer bien deco...   \n",
              "996  [jamais decue difficile choisir carte allechan...   \n",
              "997  [decue achat brioche doree forum halle 02/12/2...   \n",
              "998  [bon carte limite restaurant apiciu liste alle...   \n",
              "999  [louve musee historique long file faire tour c...   \n",
              "\n",
              "                                               ratings  \n",
              "0                                                [4.0]  \n",
              "1    [5.0, 4.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, 5.0, ...  \n",
              "2                                           [5.0, 3.0]  \n",
              "3                                      [4.0, 5.0, 5.0]  \n",
              "4    [4.0, 3.0, 5.0, 4.0, 4.0, 4.0, 3.0, 5.0, 1.0, ...  \n",
              "..                                                 ...  \n",
              "995  [5.0, 5.0, 5.0, 5.0, 5.0, 3.0, 5.0, 4.0, 5.0, ...  \n",
              "996  [5.0, 5.0, 5.0, 4.0, 5.0, 5.0, 1.0, 5.0, 5.0, ...  \n",
              "997                          [3.0, 1.0, 4.0, 5.0, 3.0]  \n",
              "998  [4.0, 5.0, 5.0, 3.0, 5.0, 1.0, 5.0, 3.0, 1.0, ...  \n",
              "999                                              [4.0]  \n",
              "\n",
              "[1000 rows x 13 columns]"
            ]
          },
          "execution_count": 45,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clean_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {},
      "outputs": [],
      "source": [
        "clean_data.to_json(\"/Users/luciegabagnou/Documents/MOSEF/PYTHON/projet_trip_advisor/sentiment_analysis_tripadvisor/data/clean_data.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.preprocessor.global_processor import ProcessingPipeline\n",
        "ProcessingPipeline(\"data/fetch_data.json\").run_pipeline()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to                       (0 + 8) / 20]\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to\n",
            "[nltk_data]     /Users/luciegabagnou/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "ERROR:root:KeyboardInterrupt while sending command.                (8 + 8) / 20]\n",
            "Traceback (most recent call last):\n",
            "  File \"/Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/java_gateway.py\", line 1038, in send_command\n",
            "    response = connection.send_command(command)\n",
            "  File \"/Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/clientserver.py\", line 475, in send_command\n",
            "    answer = smart_decode(self.stream.readline()[:-1])\n",
            "  File \"/Users/luciegabagnou/opt/anaconda3/envs/scrap/lib/python3.9/socket.py\", line 704, in readinto\n",
            "    return self._sock.recv_into(b)\n",
            "KeyboardInterrupt\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m ProcessingPipeline(\u001b[39m\"\u001b[39;49m\u001b[39mdata/fetch_data.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\u001b[39m.\u001b[39;49mrun_pipeline()\n",
            "Cell \u001b[0;32mIn[13], line 104\u001b[0m, in \u001b[0;36mProcessingPipeline.run_pipeline\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_geocode_location()\n\u001b[1;32m    103\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcleaning_text()\n\u001b[0;32m--> 104\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_json(\n\u001b[1;32m    105\u001b[0m     os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mdirname(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mjson_filepath), \u001b[39m\"\u001b[39;49m\u001b[39mclean_data.json\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    106\u001b[0m )\n",
            "Cell \u001b[0;32mIn[13], line 94\u001b[0m, in \u001b[0;36mProcessingPipeline.save_json\u001b[0;34m(self, save_path)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39msave_json\u001b[39m(\u001b[39mself\u001b[39m, save_path):\n\u001b[1;32m     90\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[39m    save the dataframe in json format\u001b[39;00m\n\u001b[1;32m     92\u001b[0m \u001b[39m    :param save_path: string, the path to save the json file\u001b[39;00m\n\u001b[1;32m     93\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdf\u001b[39m.\u001b[39;49mwrite\u001b[39m.\u001b[39;49mjson(save_path, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39moverwrite\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/pyspark/sql/readwriter.py:846\u001b[0m, in \u001b[0;36mDataFrameWriter.json\u001b[0;34m(self, path, mode, compression, dateFormat, timestampFormat, lineSep, encoding, ignoreNullFields)\u001b[0m\n\u001b[1;32m    842\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmode(mode)\n\u001b[1;32m    843\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_opts(\n\u001b[1;32m    844\u001b[0m     compression\u001b[39m=\u001b[39mcompression, dateFormat\u001b[39m=\u001b[39mdateFormat, timestampFormat\u001b[39m=\u001b[39mtimestampFormat,\n\u001b[1;32m    845\u001b[0m     lineSep\u001b[39m=\u001b[39mlineSep, encoding\u001b[39m=\u001b[39mencoding, ignoreNullFields\u001b[39m=\u001b[39mignoreNullFields)\n\u001b[0;32m--> 846\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_jwrite\u001b[39m.\u001b[39;49mjson(path)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/java_gateway.py:1320\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1313\u001b[0m args_command, temp_args \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_args(\u001b[39m*\u001b[39margs)\n\u001b[1;32m   1315\u001b[0m command \u001b[39m=\u001b[39m proto\u001b[39m.\u001b[39mCALL_COMMAND_NAME \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcommand_header \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[39m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[39m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m-> 1320\u001b[0m answer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgateway_client\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1321\u001b[0m return_value \u001b[39m=\u001b[39m get_return_value(\n\u001b[1;32m   1322\u001b[0m     answer, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgateway_client, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget_id, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mname)\n\u001b[1;32m   1324\u001b[0m \u001b[39mfor\u001b[39;00m temp_arg \u001b[39min\u001b[39;00m temp_args:\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/java_gateway.py:1038\u001b[0m, in \u001b[0;36mGatewayClient.send_command\u001b[0;34m(self, command, retry, binary)\u001b[0m\n\u001b[1;32m   1036\u001b[0m connection \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_connection()\n\u001b[1;32m   1037\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1038\u001b[0m     response \u001b[39m=\u001b[39m connection\u001b[39m.\u001b[39;49msend_command(command)\n\u001b[1;32m   1039\u001b[0m     \u001b[39mif\u001b[39;00m binary:\n\u001b[1;32m   1040\u001b[0m         \u001b[39mreturn\u001b[39;00m response, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_connection_guard(connection)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/site-packages/py4j/clientserver.py:475\u001b[0m, in \u001b[0;36mClientServerConnection.send_command\u001b[0;34m(self, command)\u001b[0m\n\u001b[1;32m    473\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    474\u001b[0m     \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 475\u001b[0m         answer \u001b[39m=\u001b[39m smart_decode(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstream\u001b[39m.\u001b[39;49mreadline()[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m])\n\u001b[1;32m    476\u001b[0m         logger\u001b[39m.\u001b[39mdebug(\u001b[39m\"\u001b[39m\u001b[39mAnswer received: \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(answer))\n\u001b[1;32m    477\u001b[0m         \u001b[39m# Happens when a the other end is dead. There might be an empty\u001b[39;00m\n\u001b[1;32m    478\u001b[0m         \u001b[39m# answer before the socket raises an error.\u001b[39;00m\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/scrap/lib/python3.9/socket.py:704\u001b[0m, in \u001b[0;36mSocketIO.readinto\u001b[0;34m(self, b)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 704\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_sock\u001b[39m.\u001b[39;49mrecv_into(b)\n\u001b[1;32m    705\u001b[0m     \u001b[39mexcept\u001b[39;00m timeout:\n\u001b[1;32m    706\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_timeout_occurred \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "ProcessingPipeline(\"data/fetch_data.json\").run_pipeline()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.16",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "vscode": {
      "interpreter": {
        "hash": "fa67bb4265ed4c5df64e99bc87edf59977441b3ddeff84fb7176f27802866c47"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
